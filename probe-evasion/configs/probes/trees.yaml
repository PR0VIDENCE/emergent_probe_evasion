# Probe training configuration for "trees" concept
# Preliminary experiments on Qwen2.5 32B Instruct (64 layers)
concept: trees
probe_type: linear
training_samples: 400

# Layer selection: 5 evenly-spaced layers across 64-layer model
# Avoiding layers 0-5 (embedding-adjacent) and 58-63 (output-adjacent)
target_layers:
  - 8
  - 20
  - 32
  - 44
  - 56

# 4 random seeds for the ensemble at each layer
random_seeds:
  - 42
  - 123
  - 456
  - 789

# Training hyperparameters
training:
  learning_rate: 0.001
  num_epochs: 100
  batch_size: 32
  weight_decay: 0.01
  patience: 10

# Dataset split ratios
split:
  train: 0.8
  val: 0.1
  test: 0.1

# Activation extraction
pooling: last_token
